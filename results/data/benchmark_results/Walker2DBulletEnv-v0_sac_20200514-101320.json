{"num_workers": 0, "num_envs_per_worker": 1, "sample_batch_size": 1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 256, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "mujoco_model", "custom_action_dist": null, "custom_options": {}, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": true, "env_config": {"reward_scale": 30}, "env": "Walker2DBulletEnv-v0", "normalize_actions": true, "clip_rewards": null, "clip_actions": false, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": {"on_episode_start": null, "on_episode_step": null, "on_episode_end": null, "on_sample_end": null, "on_train_result": null, "on_postprocess_traj": null}, "ignore_worker_failures": false, "log_sys_usage": true, "use_pytorch": false, "eager": false, "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 1, "evaluation_num_episodes": 5, "in_evaluation": false, "evaluation_config": {"explore": false, "exploration_fraction": 0, "evaluation_num_workers": 0, "evaluation_num_episodes": 5, "batch_mode": "complete_episodes", "horizon": Infinity, "sample_batch_size": 1, "collect_metrics_timeout": Infinity}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {}, "policy_mapping_fn": null, "policies_to_train": null}, "twin_q": true, "use_state_preprocessor": false, "policy": "GaussianLatentSpacePolicy", "Q_model": {"hidden_activation": "relu", "hidden_layer_sizes": [256, 256]}, "policy_model": {"hidden_activation": "relu", "hidden_layer_sizes": [256, 256]}, "tau": 0.005, "target_entropy": "auto", "n_step": 1, "buffer_size": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "prioritized_replay_beta_annealing_timesteps": 20000, "final_prioritized_replay_beta": 0.4, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_norm_clipping": null, "learning_starts": 10000, "target_network_update_freq": 1, "worker_side_prioritization": false}